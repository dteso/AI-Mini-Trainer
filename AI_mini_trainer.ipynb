{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSQ7/QF0RA5L0GNSUfvvuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dteso/AI-Mini-Trainer/blob/main/AI_mini_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio scikit-learn pandas plotly atomicwrites"
      ],
      "metadata": {
        "id": "kyc-HbLlkucd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qquUaEtQkbgu"
      },
      "outputs": [],
      "source": [
        "### ML Mini Trainer - v1.0.0\n",
        "### DAVID TESO POZO\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os, json, pickle, warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "from atomicwrites import atomic_write\n",
        "\n",
        "# ---------------------------\n",
        "# IMPORTACIONES DE SKLEARN\n",
        "# ---------------------------\n",
        "from sklearn.datasets import (\n",
        "    load_iris, load_wine, load_breast_cancer, load_digits,\n",
        "    load_diabetes, fetch_california_housing, load_linnerud,\n",
        "    make_regression, make_friedman1\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ---------------------------\n",
        "# CONFIGURACIÓN: DATASETS Y MODELOS\n",
        "# ---------------------------\n",
        "available_datasets = {\n",
        "    \"Iris (Clasificación)\": load_iris,\n",
        "    \"Wine (Clasificación)\": load_wine,\n",
        "    \"Breast Cancer (Clasificación)\": load_breast_cancer,\n",
        "    \"Digits (Clasificación)\": load_digits,\n",
        "    \"Linnerud (Clasificación - multietiqueta)\": load_linnerud,\n",
        "    \"Diabetes (Regresión)\": load_diabetes,\n",
        "    \"California Housing (Regresión)\": fetch_california_housing,\n",
        "    \"Friedman1 (Regresión sintética)\": lambda: {\n",
        "        \"data\": make_friedman1(n_samples=200, n_features=10, random_state=42)[0],\n",
        "        \"target\": make_friedman1(n_samples=200, n_features=10, random_state=42)[1],\n",
        "        \"feature_names\": [f\"X{i}\" for i in range(10)]\n",
        "    },\n",
        "    \"Make Regression (Regresión sintética)\": lambda: {\n",
        "        \"data\": make_regression(n_samples=200, n_features=8, noise=0.1, random_state=42)[0],\n",
        "        \"target\": make_regression(n_samples=200, n_features=8, noise=0.1, random_state=42)[1],\n",
        "        \"feature_names\": [f\"X{i}\" for i in range(8)]\n",
        "    },\n",
        "}\n",
        "classification_models = {\n",
        "    \"Logistic Regression\": LogisticRegression,\n",
        "    \"KNN Classifier\": KNeighborsClassifier,\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier,\n",
        "    \"Random Forest Classifier\": RandomForestClassifier,\n",
        "    \"SVC\": SVC,\n",
        "    \"Naive Bayes\": GaussianNB,\n",
        "}\n",
        "regression_models = {\n",
        "    \"Linear Regression\": LinearRegression,\n",
        "    \"Random Forest Regressor\": RandomForestRegressor\n",
        "}\n",
        "available_models = {**classification_models, **regression_models}\n",
        "\n",
        "# ---------------------------\n",
        "# FUNCIONES DE APOYO\n",
        "# ---------------------------\n",
        "def load_dataset(name):\n",
        "    dataset = available_datasets[name]()\n",
        "    df = pd.DataFrame(dataset[\"data\"],\n",
        "                      columns=dataset.get(\"feature_names\",\n",
        "                                          [f\"X{i}\" for i in range(dataset[\"data\"].shape[1])]))\n",
        "    target = pd.Series(dataset[\"target\"], name=\"target\")\n",
        "    return df, target\n",
        "\n",
        "def is_classification_task(target):\n",
        "    return pd.Series(target).nunique() < 20 and pd.api.types.is_integer_dtype(target)\n",
        "\n",
        "def show_dataset_with_target(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    # añadimos la columna 'class' para mostrar labels si hay target_names\n",
        "    dataset = available_datasets[dataset_name]()\n",
        "    if \"target_names\" in dataset:\n",
        "        try:\n",
        "            labels = pd.Series(dataset[\"target\"])\\\n",
        "                       .apply(lambda x: dataset[\"target_names\"][x])\n",
        "        except:\n",
        "            labels = dataset[\"target\"]\n",
        "    else:\n",
        "        labels = dataset[\"target\"]\n",
        "    df[\"class\"] = labels\n",
        "    return df, f\"Vista del Dataset ({len(df)} elementos)\"\n",
        "\n",
        "def update_model_choices(dataset_name):\n",
        "    df, target = load_dataset(dataset_name)\n",
        "    if is_classification_task(target):\n",
        "        return gr.update(choices=list(classification_models.keys()),\n",
        "                         value=list(classification_models.keys())[0])\n",
        "    else:\n",
        "        return gr.update(choices=list(regression_models.keys()),\n",
        "                         value=list(regression_models.keys())[0])\n",
        "\n",
        "def train_multiple_models(dataset_name, model_names, test_size):\n",
        "    df, target = load_dataset(dataset_name)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df, target,\n",
        "                                                        test_size=test_size,\n",
        "                                                        random_state=42)\n",
        "    results = []\n",
        "    is_classif = is_classification_task(target)\n",
        "    for name in model_names:\n",
        "        ModelClass = available_models[name]\n",
        "        model = ModelClass()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        if is_classif:\n",
        "            metric = accuracy_score(y_test, y_pred)\n",
        "            report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        else:\n",
        "            metric = r2_score(y_test, y_pred)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            report = {\"R2 Score\": metric, \"MSE\": mse}\n",
        "        results.append({\"Modelo\": name, \"Precisión\": metric, \"Reporte\": report})\n",
        "    return results\n",
        "\n",
        "def plot_accuracy_comparison(results):\n",
        "    fig, ax = plt.subplots()\n",
        "    metrics = [r[\"Precisión\"] for r in results]\n",
        "    sns.barplot(x=[r[\"Modelo\"] for r in results], y=metrics, ax=ax)\n",
        "    if all(0 <= m <= 1 for m in metrics):\n",
        "        ax.set_ylim(0, 1); ax.set_ylabel(\"Precisión\")\n",
        "    else:\n",
        "        ax.set_ylabel(\"R2 Score\")\n",
        "    ax.set_title(\"Comparación de Modelos\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def export_reports_as_csv(results):\n",
        "    df = pd.DataFrame([{\"Modelo\": r[\"Modelo\"], \"Precisión\": r[\"Precisión\"]} for r in results])\n",
        "    return df.to_csv(index=False)\n",
        "\n",
        "def full_training(dataset_name, selected_models, test_size):\n",
        "    results = train_multiple_models(dataset_name, selected_models, test_size)\n",
        "    df_res = pd.DataFrame([{\"Modelo\": r[\"Modelo\"], \"Precisión\": round(r[\"Precisión\"],4)} for r in results])\\\n",
        "               .sort_values(by=\"Precisión\", ascending=False)\n",
        "    fig = plot_accuracy_comparison(results)\n",
        "    csv_str = export_reports_as_csv(results)\n",
        "    csv_path = \"report.csv\"\n",
        "    with open(csv_path, \"w\") as f:\n",
        "        f.write(csv_str)\n",
        "    return df_res, fig, csv_path\n",
        "\n",
        "def run_eda(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    return df.describe().reset_index()\n",
        "\n",
        "def plot_eda(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    df_m = df.melt(var_name=\"feature\", value_name=\"valor\")\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    sns.boxplot(data=df_m, x=\"feature\", y=\"valor\",\n",
        "                hue=\"feature\", palette=\"Set2\", dodge=False, ax=ax)\n",
        "    leg = ax.get_legend()\n",
        "    if leg: leg.remove()\n",
        "    ax.set_title(\"Distribución por Feature (Boxplot)\", fontsize=14, weight=\"bold\")\n",
        "    ax.set_xlabel(\"Feature\"); ax.set_ylabel(\"Valor\")\n",
        "    ax.tick_params(axis=\"x\", rotation=30)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def run_pca(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    pca = PCA(n_components=2)\n",
        "    comps = pca.fit_transform(df)\n",
        "    df_pca = pd.DataFrame(comps, columns=[\"PC1\",\"PC2\"])\n",
        "    dataset = available_datasets[dataset_name]()\n",
        "    if \"target_names\" in dataset:\n",
        "        try:\n",
        "            labels = pd.Series(dataset[\"target\"]).apply(lambda x: dataset[\"target_names\"][x])\n",
        "        except:\n",
        "            labels = dataset[\"target\"]\n",
        "    else:\n",
        "        labels = dataset[\"target\"]\n",
        "    df_pca[\"Clase\"] = labels\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    sns.scatterplot(data=df_pca, x=\"PC1\", y=\"PC2\",\n",
        "                    hue=\"Clase\", palette=\"Set2\", s=60, ax=ax)\n",
        "    ax.set_title(\"PCA - 2 Componentes\", fontsize=14, weight=\"bold\")\n",
        "    ax.set_xlabel(\"PC1\"); ax.set_ylabel(\"PC2\"); ax.legend(title=\"Clase\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ---------------------------\n",
        "# HIPERPARÁMETROS DE MODELOS\n",
        "# ---------------------------\n",
        "model_params_demo = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": {\"type\":\"slider\",\"min\":0.01,\"max\":10.0,\"value\":1.0,\"step\":0.01,\"label\":\"C (Regularización)\"},\n",
        "        \"max_iter\": {\"type\":\"slider\",\"min\":100,\"max\":2000,\"value\":1000,\"step\":100,\"label\":\"Iteraciones Máx.\"}\n",
        "    },\n",
        "    \"KNN Classifier\": {\n",
        "        \"n_neighbors\": {\"type\":\"slider\",\"min\":1,\"max\":30,\"value\":5,\"step\":1,\"label\":\"n_neighbors\"}\n",
        "    },\n",
        "    \"Decision Tree Classifier\": {\n",
        "        \"max_depth\": {\"type\":\"slider\",\"min\":1,\"max\":20,\"value\":10,\"step\":1,\"label\":\"max_depth\"},\n",
        "        \"min_samples_split\": {\"type\":\"slider\",\"min\":2,\"max\":20,\"value\":2,\"step\":1,\"label\":\"min_samples_split\"}\n",
        "    },\n",
        "    \"Random Forest Classifier\": {\n",
        "        \"n_estimators\": {\"type\":\"slider\",\"min\":10,\"max\":200,\"value\":100,\"step\":10,\"label\":\"n_estimators\"},\n",
        "        \"max_depth\": {\"type\":\"slider\",\"min\":1,\"max\":20,\"value\":10,\"step\":1,\"label\":\"max_depth\"}\n",
        "    },\n",
        "    \"SVC\": {\n",
        "        \"C\": {\"type\":\"slider\",\"min\":0.1,\"max\":10.0,\"value\":1.0,\"step\":0.1,\"label\":\"C\"},\n",
        "        \"gamma\": {\"type\":\"slider\",\"min\":0.001,\"max\":1.0,\"value\":0.01,\"step\":0.001,\"label\":\"gamma\"}\n",
        "    },\n",
        "    \"Random Forest Regressor\": {\n",
        "        \"n_estimators\": {\"type\":\"slider\",\"min\":10,\"max\":200,\"value\":100,\"step\":10,\"label\":\"n_estimators\"},\n",
        "        \"max_depth\": {\"type\":\"slider\",\"min\":1,\"max\":20,\"value\":5,\"step\":1,\"label\":\"max_depth\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "def fix_slider_params(params):\n",
        "    p = params.copy()\n",
        "    # Para Gradio: 'minimum'/'maximum'\n",
        "    if \"min\" in p: p[\"minimum\"] = p.pop(\"min\")\n",
        "    if \"max\" in p: p[\"maximum\"] = p.pop(\"max\")\n",
        "    return p\n",
        "\n",
        "# ---------------------------\n",
        "# GUARDAR/REGISTRAR MODELOS\n",
        "# ---------------------------\n",
        "def save_model_locally(model, model_save_name, headers, target_names=None):\n",
        "    model_dir = \"models\"; os.makedirs(model_dir, exist_ok=True)\n",
        "    if not model_save_name.endswith(\".pkl\"): model_save_name += \".pkl\"\n",
        "    model_path = os.path.join(model_dir, model_save_name)\n",
        "    # pickle\n",
        "    with open(model_path, \"wb\") as f:\n",
        "        pickle.dump({\"model\":model,\"headers\":headers,\"target_names\":target_names}, f)\n",
        "    # serializable\n",
        "    if isinstance(target_names, np.ndarray): tns = target_names.tolist()\n",
        "    elif isinstance(target_names, (list,tuple)): tns = target_names\n",
        "    else: tns = None\n",
        "    # registry\n",
        "    rp = \"model_registry.json\"\n",
        "    registry = json.load(open(rp)) if os.path.exists(rp) else {}\n",
        "    registry[model_save_name] = {\"model_path\":model_path,\"headers\":headers,\"target_names\":tns}\n",
        "    with atomic_write(rp, overwrite=True, encoding=\"utf-8\") as f:\n",
        "        json.dump(registry, f, indent=4)\n",
        "    return model_path, registry\n",
        "\n",
        "# ---------------------------\n",
        "# ENTRENAMIENTO INDIVIDUAL\n",
        "# ---------------------------\n",
        "def train_one_model_with_save(dataset_name, model_name, test_size,\n",
        "                              val1, val2, val3, val4):\n",
        "    df, target = load_dataset(dataset_name)\n",
        "    headers = df.columns.tolist()\n",
        "    dataset = available_datasets[dataset_name]()\n",
        "    tns = dataset.get(\"target_names\", None)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df, target,\n",
        "                                                        test_size=test_size,\n",
        "                                                        random_state=42)\n",
        "    # Hiperparámetros\n",
        "    if model_name in classification_models:\n",
        "        demo = model_params_demo[model_name]\n",
        "        # extraemos valores\n",
        "        if model_name==\"Logistic Regression\":\n",
        "            hyper = {\"C\": val1, \"max_iter\": int(round(val2))}\n",
        "        elif model_name==\"KNN Classifier\":\n",
        "            hyper = {\"n_neighbors\": int(round(val1))}\n",
        "        elif model_name==\"Decision Tree Classifier\":\n",
        "            hyper = {\"max_depth\": int(round(val1)),\n",
        "                     \"min_samples_split\": int(round(val2))}\n",
        "        elif model_name==\"Random Forest Classifier\":\n",
        "            hyper = {\"n_estimators\": int(round(val1)),\n",
        "                     \"max_depth\": int(round(val2))}\n",
        "        elif model_name==\"SVC\":\n",
        "            hyper = {\"C\": val1, \"gamma\": val2}\n",
        "        else:\n",
        "            hyper = {}\n",
        "    else:\n",
        "        # regresión\n",
        "        if model_name==\"Random Forest Regressor\":\n",
        "            hyper = {\"n_estimators\": int(round(val1)),\n",
        "                     \"max_depth\": int(round(val2))}\n",
        "        else:\n",
        "            hyper = {}\n",
        "    ModelClass = available_models.get(model_name)\n",
        "    if not ModelClass:\n",
        "        return \"Modelo no válido\", None, pd.DataFrame(), None, None\n",
        "    model = ModelClass(**hyper)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Métrica y figura\n",
        "    if model_name in classification_models:\n",
        "        metric = accuracy_score(y_test, y_pred)\n",
        "        mname = \"Accuracy\"\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "        ax.set_title(\"Confusion Matrix\")\n",
        "        table_df = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred})\n",
        "    else:\n",
        "        metric = r2_score(y_test, y_pred)\n",
        "        mname = \"R2 Score\"\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(y_test, y_pred)\n",
        "        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
        "                \"k--\", lw=2)\n",
        "        ax.set_xlabel(\"Actual\"); ax.set_ylabel(\"Predicted\")\n",
        "        ax.set_title(\"Actual vs Predicted\")\n",
        "        table_df = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
        "    state = {\"model\": model, \"headers\": headers, \"target_names\": tns}\n",
        "    return f\"{mname}: {metric:.4f}\", fig, table_df, state, hyper\n",
        "\n",
        "# ---------------------------\n",
        "# UTILIDADES PARA PREDICCIÓN\n",
        "# ---------------------------\n",
        "MAX_FEATURES = 20\n",
        "\n",
        "def load_model_registry():\n",
        "    rp = \"model_registry.json\"\n",
        "    if os.path.exists(rp):\n",
        "        try: return list(json.load(open(rp)).keys())\n",
        "        except: return []\n",
        "    return []\n",
        "\n",
        "def refresh_model_list():\n",
        "    return gr.update(choices=load_model_registry())\n",
        "\n",
        "def update_textboxes_from_saved_model(model_name):\n",
        "    rp = \"model_registry.json\"\n",
        "    if not os.path.exists(rp):\n",
        "        return [gr.update(visible=False) for _ in range(MAX_FEATURES)]\n",
        "    reg = json.load(open(rp))\n",
        "    headers = reg.get(model_name, {}).get(\"headers\", [])\n",
        "    updates = []\n",
        "    for i in range(MAX_FEATURES):\n",
        "        if i < len(headers):\n",
        "            updates.append(gr.update(label=headers[i], visible=True, value=\"\"))\n",
        "        else:\n",
        "            updates.append(gr.update(visible=False))\n",
        "    return updates\n",
        "\n",
        "def predict_model_combined(model_name, excel_file, *features):\n",
        "    rp = \"model_registry.json\"\n",
        "    if not os.path.exists(rp): return None, \"No hay modelos guardados.\"\n",
        "    reg = json.load(open(rp))\n",
        "    if model_name not in reg: return None, \"Modelo no encontrado.\"\n",
        "    data = pickle.load(open(reg[model_name][\"model_path\"], \"rb\"))\n",
        "    model, headers, tns = data[\"model\"], data[\"headers\"], data.get(\"target_names\", None)\n",
        "    def mp(p):\n",
        "        if tns is not None:\n",
        "            try: return tns[int(p)]\n",
        "            except: return p\n",
        "        return p\n",
        "    # Masiva\n",
        "    if excel_file is not None:\n",
        "        df = pd.read_excel(excel_file.name)\n",
        "        if not set(headers).issubset(df.columns):\n",
        "            return None, f\"Faltan columnas: {headers}\"\n",
        "        preds = model.predict(df[headers])\n",
        "        df[\"Predicción\"] = [mp(p) for p in preds]\n",
        "        return df, \"\"\n",
        "    # Individual\n",
        "    vals = []\n",
        "    for i in range(len(headers)):\n",
        "        s = features[i] if i < len(features) else \"\"\n",
        "        if s.strip():\n",
        "            try: vals.append(float(s))\n",
        "            except: return None, \"Todos los features deben ser numéricos.\"\n",
        "        else:\n",
        "            vals.append(0.0)\n",
        "    row = pd.DataFrame([vals], columns=headers)\n",
        "    p = model.predict(row)[0]\n",
        "    return None, f\"Predicción: {mp(p)}\"\n",
        "\n",
        "def predict_individual(model_name, *features):\n",
        "    _, msg = predict_model_combined(model_name, None, *features)\n",
        "    return f\"<h2>{msg}</h2>\"\n",
        "\n",
        "def predict_bulk(model_name, excel_file):\n",
        "    df, _ = predict_model_combined(model_name, excel_file)\n",
        "    return df\n",
        "\n",
        "def generate_excel_template(model_name):\n",
        "    rp = \"model_registry.json\"\n",
        "    if not os.path.exists(rp): return None\n",
        "    reg = json.load(open(rp))\n",
        "    if model_name not in reg: return None\n",
        "    headers = reg[model_name].get(\"headers\", [])\n",
        "    df = pd.DataFrame(columns=headers)\n",
        "    # nombre dinámico\n",
        "    safe = \"\".join(c if c.isalnum() else \"_\" for c in model_name)\n",
        "    fname = f\"{safe}_plantilla.xlsx\"\n",
        "    df.to_excel(fname, index=False)\n",
        "    return fname\n",
        "\n",
        "# Modelo dropdown inicia vacío\n",
        "initial_models = load_model_registry()\n",
        "\n",
        "# ---------------------------\n",
        "# INTERFAZ GRADIO PRINCIPAL\n",
        "# ---------------------------\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    # Pestaña 1: Dataset + Modelos ML\n",
        "    with gr.Tab(\"Dataset + Modelos ML\"):\n",
        "        gr.Markdown(\"## Visualización de Dataset y Comparación de Modelos (múltiples)\")\n",
        "        with gr.Row():\n",
        "            ds_sel = gr.Dropdown(list(available_datasets.keys()), value=\"Iris (Clasificación)\", label=\"Dataset\")\n",
        "            models_cb = gr.CheckboxGroup(list(classification_models.keys()), value=list(classification_models.keys()), label=\"Modelos\")\n",
        "            ts = gr.Slider(0.1,0.5,0.3,0.05, label=\"Test size\")\n",
        "        btn_train = gr.Button(\"Entrenar y Comparar\")\n",
        "        tbl_res = gr.Dataframe(headers=[\"Modelo\",\"Precisión\"], label=\"Resultados\")\n",
        "        plot_res = gr.Plot(label=\"Gráfica\")\n",
        "        file_res = gr.File(label=\"Reporte CSV\")\n",
        "        btn_train.click(full_training, [ds_sel, models_cb, ts], [tbl_res, plot_res, file_res])\n",
        "\n",
        "        df0, lbl0 = show_dataset_with_target(\"Iris (Clasificación)\")\n",
        "        dt = gr.Dataframe(value=df0); md = gr.Markdown(lbl0)\n",
        "        ds_sel.change(show_dataset_with_target, ds_sel, [dt, md])\n",
        "        ds_sel.change(update_model_choices, ds_sel, models_cb)\n",
        "\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"EDA\"):\n",
        "                eda_tbl = gr.Dataframe(value=run_eda(\"Iris (Clasificación)\"))\n",
        "                eda_plt = gr.Plot(value=plot_eda(\"Iris (Clasificación)\"))\n",
        "            with gr.Tab(\"PCA\"):\n",
        "                pca_plt = gr.Plot(value=run_pca(\"Iris (Clasificación)\"))\n",
        "        ds_sel.change(run_eda, ds_sel, eda_tbl)\n",
        "        ds_sel.change(plot_eda, ds_sel, eda_plt)\n",
        "        ds_sel.change(run_pca, ds_sel, pca_plt)\n",
        "\n",
        "    # Pestaña 2: Entrenamiento individual\n",
        "    with gr.Tab(\"Entrenamiento\"):\n",
        "        gr.Markdown(\"## Entrenamiento de un solo modelo\")\n",
        "        ds_tr = gr.Dropdown(list(available_datasets.keys()), value=\"Iris (Clasificación)\", label=\"Dataset\")\n",
        "        mdl_tr = gr.Dropdown(list(classification_models.keys()), value=list(classification_models.keys())[0], label=\"Modelo\")\n",
        "        ds_tr.change(update_model_choices, ds_tr, mdl_tr)\n",
        "        ts_tr = gr.Slider(0.1,0.5,0.3,0.05, label=\"Test size\")\n",
        "\n",
        "        # Logistic Regression sliders\n",
        "        lr_Cp = fix_slider_params(model_params_demo[\"Logistic Regression\"][\"C\"])\n",
        "        lr_Itp = fix_slider_params(model_params_demo[\"Logistic Regression\"][\"max_iter\"])\n",
        "        c_sl = gr.Slider(minimum=lr_Cp[\"minimum\"], maximum=lr_Cp[\"maximum\"],\n",
        "                         step=lr_Cp[\"step\"], value=lr_Cp[\"value\"], label=lr_Cp[\"label\"])\n",
        "        it_sl = gr.Slider(minimum=lr_Itp[\"minimum\"], maximum=lr_Itp[\"maximum\"],\n",
        "                          step=lr_Itp[\"step\"], value=lr_Itp[\"value\"], label=lr_Itp[\"label\"])\n",
        "        # Random Forest Regressor sliders\n",
        "        rf_Nep = fix_slider_params(model_params_demo[\"Random Forest Regressor\"][\"n_estimators\"])\n",
        "        rf_Mdp = fix_slider_params(model_params_demo[\"Random Forest Regressor\"][\"max_depth\"])\n",
        "        ne_sl = gr.Slider(minimum=rf_Nep[\"minimum\"], maximum=rf_Nep[\"maximum\"],\n",
        "                          step=rf_Nep[\"step\"], value=rf_Nep[\"value\"], label=rf_Nep[\"label\"], visible=False)\n",
        "        md_sl = gr.Slider(minimum=rf_Mdp[\"minimum\"], maximum=rf_Mdp[\"maximum\"],\n",
        "                          step=rf_Mdp[\"step\"], value=rf_Mdp[\"value\"], label=rf_Mdp[\"label\"], visible=False)\n",
        "\n",
        "        def show_params(name):\n",
        "            if name==\"Logistic Regression\":\n",
        "                return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "            elif name==\"Random Forest Regressor\":\n",
        "                return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True), gr.update(visible=True)\n",
        "            else:\n",
        "                return (gr.update(visible=False),)*4\n",
        "\n",
        "        mdl_tr.change(show_params, mdl_tr, [c_sl, it_sl, ne_sl, md_sl])\n",
        "\n",
        "        btn_tr1 = gr.Button(\"Entrenar\")\n",
        "        md_out = gr.Markdown()\n",
        "        plt_out = gr.Plot()\n",
        "        tbl_out = gr.Dataframe()\n",
        "        st = gr.State()\n",
        "        btn_tr1.click(train_one_model_with_save,\n",
        "                      inputs=[ds_tr, mdl_tr, ts_tr, c_sl, it_sl, ne_sl, md_sl],\n",
        "                      outputs=[md_out, plt_out, tbl_out, st])\n",
        "\n",
        "        save_name = gr.Textbox(label=\"Nombre modelo\")\n",
        "        btn_save = gr.Button(\"Guardar\")\n",
        "        def do_save(state, name):\n",
        "            if not state: return \"Nada que guardar\"\n",
        "            path, _ = save_model_locally(state[\"model\"], name, state[\"headers\"], state[\"target_names\"])\n",
        "            return f\"Guardado en {path}\"\n",
        "        btn_save.click(do_save, [st, save_name], md_out)\n",
        "\n",
        "    # Pestaña 3: Predicción (Individual / Masiva)\n",
        "    with gr.Tab(\"Predicción\"):\n",
        "        gr.Markdown(\"## Predicción\\n- **Individual** vs **Masiva**\")\n",
        "\n",
        "        # Ahora sin placeholder\n",
        "        model_dd = gr.Dropdown(\n",
        "            choices=load_model_registry(),\n",
        "            value=None,\n",
        "            label=\"Modelos guardados\"\n",
        "        )\n",
        "\n",
        "        btn_ref = gr.Button(\"Refrescar modelos\")\n",
        "        btn_ref.click(refresh_model_list, [], model_dd)\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Individual\n",
        "            with gr.Tab(\"Individual\"):\n",
        "                feature_inputs = [\n",
        "                    gr.Textbox(label=f\"Feature {i}\", visible=False)\n",
        "                    for i in range(MAX_FEATURES)\n",
        "                ]\n",
        "                model_dd.change(update_textboxes_from_saved_model,\n",
        "                                inputs=[model_dd],\n",
        "                                outputs=feature_inputs)\n",
        "                btn_ind = gr.Button(\"Predecir\")\n",
        "                out_ind = gr.HTML()\n",
        "                btn_ind.click(predict_individual,\n",
        "                              inputs=[model_dd] + feature_inputs,\n",
        "                              outputs=[out_ind])\n",
        "\n",
        "            # Masiva\n",
        "            with gr.Tab(\"Masiva\"):\n",
        "                tpl_btn = gr.Button(\"Generar plantilla Excel\")\n",
        "                tpl_file = gr.File(label=\"Descargar plantilla Excel\")\n",
        "                tpl_btn.click(generate_excel_template,\n",
        "                              inputs=[model_dd],\n",
        "                              outputs=[tpl_file])\n",
        "                uploader = gr.File(label=\"Cargar Excel\",\n",
        "                                   file_types=[\".xlsx\", \".xls\"])\n",
        "                btn_bulk = gr.Button(\"Predecir Masivo\")\n",
        "                out_bulk = gr.Dataframe(label=\"Resultados Masivos\")\n",
        "                btn_bulk.click(predict_bulk,\n",
        "                               inputs=[model_dd, uploader],\n",
        "                               outputs=[out_bulk])\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "38tm4diBGhsm"
      }
    }
  ]
}