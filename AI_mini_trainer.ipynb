{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPSQ7/QF0RA5L0GNSUfvvuH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dteso/AI-Mini-Trainer/blob/main/AI_mini_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio scikit-learn pandas plotly atomicwrites"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyc-HbLlkucd",
        "outputId": "a67c3796-dbed-4c22-cfd0-39a112c1f7a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.25.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Collecting atomicwrites\n",
            "  Downloading atomicwrites-1.4.1.tar.gz (14 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aiofiles<25.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==1.8.0 (from gradio)\n",
            "  Downloading gradio_client-1.8.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting groovy~=0.1 (from gradio)\n",
            "  Downloading groovy-0.1.2-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.16)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.18 (from gradio)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.9.3 (from gradio)\n",
            "  Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
            "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.2)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.8.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.8)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.25.2-py3-none-any.whl (46.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.8.0-py3-none-any.whl (322 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading ruff-0.11.6-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: atomicwrites\n",
            "  Building wheel for atomicwrites (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atomicwrites: filename=atomicwrites-1.4.1-py2.py3-none-any.whl size=6943 sha256=a879e78e42a9c20d649059a64c0bdd948ab3a7f9e2b6cd3cc24c58950d89c7c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/99/9c/d24e98c35f30eba0c367ad1e7888d396d676abb35fe1e7611c\n",
            "Successfully built atomicwrites\n",
            "Installing collected packages: pydub, uvicorn, tomlkit, semantic-version, ruff, python-multipart, groovy, ffmpy, atomicwrites, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "Successfully installed aiofiles-24.1.0 atomicwrites-1.4.1 fastapi-0.115.12 ffmpy-0.5.0 gradio-5.25.2 gradio-client-1.8.0 groovy-0.1.2 pydub-0.25.1 python-multipart-0.0.20 ruff-0.11.6 safehttpx-0.1.6 semantic-version-2.10.0 starlette-0.46.2 tomlkit-0.13.2 uvicorn-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qquUaEtQkbgu",
        "outputId": "96214489-e9cf-4739-aaf4-ff727a4015c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://7efa434a75130ba124.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7efa434a75130ba124.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-2299f632d414>:192: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
            "  plt.tight_layout()\n",
            "<ipython-input-23-2299f632d414>:169: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
            "  plt.tight_layout()\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9685\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "670        4       4\n",
            "118        7       7\n",
            "1128       0       0\n",
            "628        7       7\n",
            "522        6       6\n",
            "\n",
            "[540 rows x 2 columns], {'model': LogisticRegression(C=1, max_iter=1000), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 1, 'max_iter': 1000}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9667\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "670        4       4\n",
            "118        7       7\n",
            "1128       0       0\n",
            "628        7       7\n",
            "522        6       6\n",
            "\n",
            "[540 rows x 2 columns], {'model': LogisticRegression(C=1.81, max_iter=1000), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 1.81, 'max_iter': 1000}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9667\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "670        4       4\n",
            "118        7       7\n",
            "1128       0       0\n",
            "628        7       7\n",
            "522        6       6\n",
            "\n",
            "[540 rows x 2 columns], {'model': LogisticRegression(C=1.81, max_iter=600), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 1.81, 'max_iter': 600}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9742\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "743        4       4\n",
            "590        5       5\n",
            "1106       0       0\n",
            "1682       5       5\n",
            "1531       2       2\n",
            "\n",
            "[310 rows x 2 columns], {'model': LogisticRegression(C=1.81, max_iter=600), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 1.81, 'max_iter': 600}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9706\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "1471       1       1\n",
            "1018       5       9\n",
            "527        1       1\n",
            "660        4       4\n",
            "1785       7       7\n",
            "\n",
            "[238 rows x 2 columns], {'model': LogisticRegression(C=1.81, max_iter=600), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 1.81, 'max_iter': 600}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9544\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "1383       8       8\n",
            "1621       1       1\n",
            "630        8       8\n",
            "1231       5       5\n",
            "1679       2       2\n",
            "\n",
            "[899 rows x 2 columns], {'model': LogisticRegression(C=1.81, max_iter=600), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 1.81, 'max_iter': 600}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9533\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "1383       8       8\n",
            "1621       1       1\n",
            "630        8       8\n",
            "1231       5       5\n",
            "1679       2       2\n",
            "\n",
            "[899 rows x 2 columns], {'model': LogisticRegression(C=10, max_iter=600), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 10, 'max_iter': 600}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9533\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "1383       8       8\n",
            "1621       1       1\n",
            "630        8       8\n",
            "1231       5       5\n",
            "1679       2       2\n",
            "\n",
            "[899 rows x 2 columns], {'model': LogisticRegression(C=10, max_iter=2000), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 10, 'max_iter': 2000}]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1855: UserWarning: A function (train_one_model_with_save) returned too many output values (needed: 4, returned: 5). Ignoring extra values.\n",
            "    Output components:\n",
            "        [markdown, plot, dataframe, state]\n",
            "    Output values returned:\n",
            "        [\"Accuracy: 0.9533\", Figure(640x480),       y_true  y_pred\n",
            "1245       6       6\n",
            "220        9       9\n",
            "1518       3       3\n",
            "438        7       7\n",
            "1270       2       2\n",
            "...      ...     ...\n",
            "1383       8       8\n",
            "1621       1       1\n",
            "630        8       8\n",
            "1231       5       5\n",
            "1679       2       2\n",
            "\n",
            "[899 rows x 2 columns], {'model': LogisticRegression(C=10, max_iter=800), 'headers': ['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7'], 'target_names': array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])}, {'C': 10, 'max_iter': 800}]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "### ML Mini Trainer - v1.0.0\n",
        "### DAVID TESO POZO\n",
        "\n",
        "\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os, json, pickle, warnings\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "from atomicwrites import atomic_write\n",
        "\n",
        "# ---------------------------\n",
        "# IMPORTACIONES DE SKLEARN\n",
        "# ---------------------------\n",
        "from sklearn.datasets import (\n",
        "    load_iris, load_wine, load_breast_cancer, load_digits,\n",
        "    load_diabetes, fetch_california_housing, load_linnerud,\n",
        "    make_regression, make_friedman1\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, r2_score, mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ---------------------------\n",
        "# CONFIGURACIÓN: DATASETS Y MODELOS\n",
        "# ---------------------------\n",
        "available_datasets = {\n",
        "    \"Iris (Clasificación)\": load_iris,\n",
        "    \"Wine (Clasificación)\": load_wine,\n",
        "    \"Breast Cancer (Clasificación)\": load_breast_cancer,\n",
        "    \"Digits (Clasificación)\": load_digits,\n",
        "    \"Linnerud (Clasificación - multietiqueta)\": load_linnerud,\n",
        "    \"Diabetes (Regresión)\": load_diabetes,\n",
        "    \"California Housing (Regresión)\": fetch_california_housing,\n",
        "    \"Friedman1 (Regresión sintética)\": lambda: {\n",
        "        \"data\": make_friedman1(n_samples=200, n_features=10, random_state=42)[0],\n",
        "        \"target\": make_friedman1(n_samples=200, n_features=10, random_state=42)[1],\n",
        "        \"feature_names\": [f\"X{i}\" for i in range(10)]\n",
        "    },\n",
        "    \"Make Regression (Regresión sintética)\": lambda: {\n",
        "        \"data\": make_regression(n_samples=200, n_features=8, noise=0.1, random_state=42)[0],\n",
        "        \"target\": make_regression(n_samples=200, n_features=8, noise=0.1, random_state=42)[1],\n",
        "        \"feature_names\": [f\"X{i}\" for i in range(8)]\n",
        "    },\n",
        "}\n",
        "classification_models = {\n",
        "    \"Logistic Regression\": LogisticRegression,\n",
        "    \"KNN Classifier\": KNeighborsClassifier,\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier,\n",
        "    \"Random Forest Classifier\": RandomForestClassifier,\n",
        "    \"SVC\": SVC,\n",
        "    \"Naive Bayes\": GaussianNB,\n",
        "}\n",
        "regression_models = {\n",
        "    \"Linear Regression\": LinearRegression,\n",
        "    \"Random Forest Regressor\": RandomForestRegressor\n",
        "}\n",
        "available_models = {**classification_models, **regression_models}\n",
        "\n",
        "# ---------------------------\n",
        "# FUNCIONES DE APOYO\n",
        "# ---------------------------\n",
        "def load_dataset(name):\n",
        "    dataset = available_datasets[name]()\n",
        "    df = pd.DataFrame(dataset[\"data\"],\n",
        "                      columns=dataset.get(\"feature_names\",\n",
        "                                          [f\"X{i}\" for i in range(dataset[\"data\"].shape[1])]))\n",
        "    target = pd.Series(dataset[\"target\"], name=\"target\")\n",
        "    return df, target\n",
        "\n",
        "def is_classification_task(target):\n",
        "    return pd.Series(target).nunique() < 20 and pd.api.types.is_integer_dtype(target)\n",
        "\n",
        "def show_dataset_with_target(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    # añadimos la columna 'class' para mostrar labels si hay target_names\n",
        "    dataset = available_datasets[dataset_name]()\n",
        "    if \"target_names\" in dataset:\n",
        "        try:\n",
        "            labels = pd.Series(dataset[\"target\"])\\\n",
        "                       .apply(lambda x: dataset[\"target_names\"][x])\n",
        "        except:\n",
        "            labels = dataset[\"target\"]\n",
        "    else:\n",
        "        labels = dataset[\"target\"]\n",
        "    df[\"class\"] = labels\n",
        "    return df, f\"Vista del Dataset ({len(df)} elementos)\"\n",
        "\n",
        "def update_model_choices(dataset_name):\n",
        "    df, target = load_dataset(dataset_name)\n",
        "    if is_classification_task(target):\n",
        "        return gr.update(choices=list(classification_models.keys()),\n",
        "                         value=list(classification_models.keys())[0])\n",
        "    else:\n",
        "        return gr.update(choices=list(regression_models.keys()),\n",
        "                         value=list(regression_models.keys())[0])\n",
        "\n",
        "def train_multiple_models(dataset_name, model_names, test_size):\n",
        "    df, target = load_dataset(dataset_name)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df, target,\n",
        "                                                        test_size=test_size,\n",
        "                                                        random_state=42)\n",
        "    results = []\n",
        "    is_classif = is_classification_task(target)\n",
        "    for name in model_names:\n",
        "        ModelClass = available_models[name]\n",
        "        model = ModelClass()\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        if is_classif:\n",
        "            metric = accuracy_score(y_test, y_pred)\n",
        "            report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        else:\n",
        "            metric = r2_score(y_test, y_pred)\n",
        "            mse = mean_squared_error(y_test, y_pred)\n",
        "            report = {\"R2 Score\": metric, \"MSE\": mse}\n",
        "        results.append({\"Modelo\": name, \"Precisión\": metric, \"Reporte\": report})\n",
        "    return results\n",
        "\n",
        "def plot_accuracy_comparison(results):\n",
        "    fig, ax = plt.subplots()\n",
        "    metrics = [r[\"Precisión\"] for r in results]\n",
        "    sns.barplot(x=[r[\"Modelo\"] for r in results], y=metrics, ax=ax)\n",
        "    if all(0 <= m <= 1 for m in metrics):\n",
        "        ax.set_ylim(0, 1); ax.set_ylabel(\"Precisión\")\n",
        "    else:\n",
        "        ax.set_ylabel(\"R2 Score\")\n",
        "    ax.set_title(\"Comparación de Modelos\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def export_reports_as_csv(results):\n",
        "    df = pd.DataFrame([{\"Modelo\": r[\"Modelo\"], \"Precisión\": r[\"Precisión\"]} for r in results])\n",
        "    return df.to_csv(index=False)\n",
        "\n",
        "def full_training(dataset_name, selected_models, test_size):\n",
        "    results = train_multiple_models(dataset_name, selected_models, test_size)\n",
        "    df_res = pd.DataFrame([{\"Modelo\": r[\"Modelo\"], \"Precisión\": round(r[\"Precisión\"],4)} for r in results])\\\n",
        "               .sort_values(by=\"Precisión\", ascending=False)\n",
        "    fig = plot_accuracy_comparison(results)\n",
        "    csv_str = export_reports_as_csv(results)\n",
        "    csv_path = \"report.csv\"\n",
        "    with open(csv_path, \"w\") as f:\n",
        "        f.write(csv_str)\n",
        "    return df_res, fig, csv_path\n",
        "\n",
        "def run_eda(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    return df.describe().reset_index()\n",
        "\n",
        "def plot_eda(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    df_m = df.melt(var_name=\"feature\", value_name=\"valor\")\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    sns.boxplot(data=df_m, x=\"feature\", y=\"valor\",\n",
        "                hue=\"feature\", palette=\"Set2\", dodge=False, ax=ax)\n",
        "    leg = ax.get_legend()\n",
        "    if leg: leg.remove()\n",
        "    ax.set_title(\"Distribución por Feature (Boxplot)\", fontsize=14, weight=\"bold\")\n",
        "    ax.set_xlabel(\"Feature\"); ax.set_ylabel(\"Valor\")\n",
        "    ax.tick_params(axis=\"x\", rotation=30)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def run_pca(dataset_name):\n",
        "    df, _ = load_dataset(dataset_name)\n",
        "    pca = PCA(n_components=2)\n",
        "    comps = pca.fit_transform(df)\n",
        "    df_pca = pd.DataFrame(comps, columns=[\"PC1\",\"PC2\"])\n",
        "    dataset = available_datasets[dataset_name]()\n",
        "    if \"target_names\" in dataset:\n",
        "        try:\n",
        "            labels = pd.Series(dataset[\"target\"]).apply(lambda x: dataset[\"target_names\"][x])\n",
        "        except:\n",
        "            labels = dataset[\"target\"]\n",
        "    else:\n",
        "        labels = dataset[\"target\"]\n",
        "    df_pca[\"Clase\"] = labels\n",
        "    sns.set(style=\"whitegrid\")\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    sns.scatterplot(data=df_pca, x=\"PC1\", y=\"PC2\",\n",
        "                    hue=\"Clase\", palette=\"Set2\", s=60, ax=ax)\n",
        "    ax.set_title(\"PCA - 2 Componentes\", fontsize=14, weight=\"bold\")\n",
        "    ax.set_xlabel(\"PC1\"); ax.set_ylabel(\"PC2\"); ax.legend(title=\"Clase\")\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ---------------------------\n",
        "# HIPERPARÁMETROS DE MODELOS\n",
        "# ---------------------------\n",
        "model_params_demo = {\n",
        "    \"Logistic Regression\": {\n",
        "        \"C\": {\"type\":\"slider\",\"min\":0.01,\"max\":10.0,\"value\":1.0,\"step\":0.01,\"label\":\"C (Regularización)\"},\n",
        "        \"max_iter\": {\"type\":\"slider\",\"min\":100,\"max\":2000,\"value\":1000,\"step\":100,\"label\":\"Iteraciones Máx.\"}\n",
        "    },\n",
        "    \"KNN Classifier\": {\n",
        "        \"n_neighbors\": {\"type\":\"slider\",\"min\":1,\"max\":30,\"value\":5,\"step\":1,\"label\":\"n_neighbors\"}\n",
        "    },\n",
        "    \"Decision Tree Classifier\": {\n",
        "        \"max_depth\": {\"type\":\"slider\",\"min\":1,\"max\":20,\"value\":10,\"step\":1,\"label\":\"max_depth\"},\n",
        "        \"min_samples_split\": {\"type\":\"slider\",\"min\":2,\"max\":20,\"value\":2,\"step\":1,\"label\":\"min_samples_split\"}\n",
        "    },\n",
        "    \"Random Forest Classifier\": {\n",
        "        \"n_estimators\": {\"type\":\"slider\",\"min\":10,\"max\":200,\"value\":100,\"step\":10,\"label\":\"n_estimators\"},\n",
        "        \"max_depth\": {\"type\":\"slider\",\"min\":1,\"max\":20,\"value\":10,\"step\":1,\"label\":\"max_depth\"}\n",
        "    },\n",
        "    \"SVC\": {\n",
        "        \"C\": {\"type\":\"slider\",\"min\":0.1,\"max\":10.0,\"value\":1.0,\"step\":0.1,\"label\":\"C\"},\n",
        "        \"gamma\": {\"type\":\"slider\",\"min\":0.001,\"max\":1.0,\"value\":0.01,\"step\":0.001,\"label\":\"gamma\"}\n",
        "    },\n",
        "    \"Random Forest Regressor\": {\n",
        "        \"n_estimators\": {\"type\":\"slider\",\"min\":10,\"max\":200,\"value\":100,\"step\":10,\"label\":\"n_estimators\"},\n",
        "        \"max_depth\": {\"type\":\"slider\",\"min\":1,\"max\":20,\"value\":5,\"step\":1,\"label\":\"max_depth\"}\n",
        "    }\n",
        "}\n",
        "\n",
        "def fix_slider_params(params):\n",
        "    p = params.copy()\n",
        "    # Para Gradio: 'minimum'/'maximum'\n",
        "    if \"min\" in p: p[\"minimum\"] = p.pop(\"min\")\n",
        "    if \"max\" in p: p[\"maximum\"] = p.pop(\"max\")\n",
        "    return p\n",
        "\n",
        "# ---------------------------\n",
        "# GUARDAR/REGISTRAR MODELOS\n",
        "# ---------------------------\n",
        "def save_model_locally(model, model_save_name, headers, target_names=None):\n",
        "    model_dir = \"models\"; os.makedirs(model_dir, exist_ok=True)\n",
        "    if not model_save_name.endswith(\".pkl\"): model_save_name += \".pkl\"\n",
        "    model_path = os.path.join(model_dir, model_save_name)\n",
        "    # pickle\n",
        "    with open(model_path, \"wb\") as f:\n",
        "        pickle.dump({\"model\":model,\"headers\":headers,\"target_names\":target_names}, f)\n",
        "    # serializable\n",
        "    if isinstance(target_names, np.ndarray): tns = target_names.tolist()\n",
        "    elif isinstance(target_names, (list,tuple)): tns = target_names\n",
        "    else: tns = None\n",
        "    # registry\n",
        "    rp = \"model_registry.json\"\n",
        "    registry = json.load(open(rp)) if os.path.exists(rp) else {}\n",
        "    registry[model_save_name] = {\"model_path\":model_path,\"headers\":headers,\"target_names\":tns}\n",
        "    with atomic_write(rp, overwrite=True, encoding=\"utf-8\") as f:\n",
        "        json.dump(registry, f, indent=4)\n",
        "    return model_path, registry\n",
        "\n",
        "# ---------------------------\n",
        "# ENTRENAMIENTO INDIVIDUAL\n",
        "# ---------------------------\n",
        "def train_one_model_with_save(dataset_name, model_name, test_size,\n",
        "                              val1, val2, val3, val4):\n",
        "    df, target = load_dataset(dataset_name)\n",
        "    headers = df.columns.tolist()\n",
        "    dataset = available_datasets[dataset_name]()\n",
        "    tns = dataset.get(\"target_names\", None)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(df, target,\n",
        "                                                        test_size=test_size,\n",
        "                                                        random_state=42)\n",
        "    # Hiperparámetros\n",
        "    if model_name in classification_models:\n",
        "        demo = model_params_demo[model_name]\n",
        "        # extraemos valores\n",
        "        if model_name==\"Logistic Regression\":\n",
        "            hyper = {\"C\": val1, \"max_iter\": int(round(val2))}\n",
        "        elif model_name==\"KNN Classifier\":\n",
        "            hyper = {\"n_neighbors\": int(round(val1))}\n",
        "        elif model_name==\"Decision Tree Classifier\":\n",
        "            hyper = {\"max_depth\": int(round(val1)),\n",
        "                     \"min_samples_split\": int(round(val2))}\n",
        "        elif model_name==\"Random Forest Classifier\":\n",
        "            hyper = {\"n_estimators\": int(round(val1)),\n",
        "                     \"max_depth\": int(round(val2))}\n",
        "        elif model_name==\"SVC\":\n",
        "            hyper = {\"C\": val1, \"gamma\": val2}\n",
        "        else:\n",
        "            hyper = {}\n",
        "    else:\n",
        "        # regresión\n",
        "        if model_name==\"Random Forest Regressor\":\n",
        "            hyper = {\"n_estimators\": int(round(val1)),\n",
        "                     \"max_depth\": int(round(val2))}\n",
        "        else:\n",
        "            hyper = {}\n",
        "    ModelClass = available_models.get(model_name)\n",
        "    if not ModelClass:\n",
        "        return \"Modelo no válido\", None, pd.DataFrame(), None, None\n",
        "    model = ModelClass(**hyper)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    # Métrica y figura\n",
        "    if model_name in classification_models:\n",
        "        metric = accuracy_score(y_test, y_pred)\n",
        "        mname = \"Accuracy\"\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
        "        ax.set_title(\"Confusion Matrix\")\n",
        "        table_df = pd.DataFrame({\"y_true\": y_test, \"y_pred\": y_pred})\n",
        "    else:\n",
        "        metric = r2_score(y_test, y_pred)\n",
        "        mname = \"R2 Score\"\n",
        "        fig, ax = plt.subplots()\n",
        "        ax.scatter(y_test, y_pred)\n",
        "        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],\n",
        "                \"k--\", lw=2)\n",
        "        ax.set_xlabel(\"Actual\"); ax.set_ylabel(\"Predicted\")\n",
        "        ax.set_title(\"Actual vs Predicted\")\n",
        "        table_df = pd.DataFrame({\"Actual\": y_test, \"Predicted\": y_pred})\n",
        "    state = {\"model\": model, \"headers\": headers, \"target_names\": tns}\n",
        "    return f\"{mname}: {metric:.4f}\", fig, table_df, state, hyper\n",
        "\n",
        "# ---------------------------\n",
        "# UTILIDADES PARA PREDICCIÓN\n",
        "# ---------------------------\n",
        "MAX_FEATURES = 20\n",
        "\n",
        "def load_model_registry():\n",
        "    rp = \"model_registry.json\"\n",
        "    if os.path.exists(rp):\n",
        "        try: return list(json.load(open(rp)).keys())\n",
        "        except: return []\n",
        "    return []\n",
        "\n",
        "def refresh_model_list():\n",
        "    return gr.update(choices=load_model_registry())\n",
        "\n",
        "def update_textboxes_from_saved_model(model_name):\n",
        "    rp = \"model_registry.json\"\n",
        "    if not os.path.exists(rp):\n",
        "        return [gr.update(visible=False) for _ in range(MAX_FEATURES)]\n",
        "    reg = json.load(open(rp))\n",
        "    headers = reg.get(model_name, {}).get(\"headers\", [])\n",
        "    updates = []\n",
        "    for i in range(MAX_FEATURES):\n",
        "        if i < len(headers):\n",
        "            updates.append(gr.update(label=headers[i], visible=True, value=\"\"))\n",
        "        else:\n",
        "            updates.append(gr.update(visible=False))\n",
        "    return updates\n",
        "\n",
        "def predict_model_combined(model_name, excel_file, *features):\n",
        "    rp = \"model_registry.json\"\n",
        "    if not os.path.exists(rp): return None, \"No hay modelos guardados.\"\n",
        "    reg = json.load(open(rp))\n",
        "    if model_name not in reg: return None, \"Modelo no encontrado.\"\n",
        "    data = pickle.load(open(reg[model_name][\"model_path\"], \"rb\"))\n",
        "    model, headers, tns = data[\"model\"], data[\"headers\"], data.get(\"target_names\", None)\n",
        "    def mp(p):\n",
        "        if tns is not None:\n",
        "            try: return tns[int(p)]\n",
        "            except: return p\n",
        "        return p\n",
        "    # Masiva\n",
        "    if excel_file is not None:\n",
        "        df = pd.read_excel(excel_file.name)\n",
        "        if not set(headers).issubset(df.columns):\n",
        "            return None, f\"Faltan columnas: {headers}\"\n",
        "        preds = model.predict(df[headers])\n",
        "        df[\"Predicción\"] = [mp(p) for p in preds]\n",
        "        return df, \"\"\n",
        "    # Individual\n",
        "    vals = []\n",
        "    for i in range(len(headers)):\n",
        "        s = features[i] if i < len(features) else \"\"\n",
        "        if s.strip():\n",
        "            try: vals.append(float(s))\n",
        "            except: return None, \"Todos los features deben ser numéricos.\"\n",
        "        else:\n",
        "            vals.append(0.0)\n",
        "    row = pd.DataFrame([vals], columns=headers)\n",
        "    p = model.predict(row)[0]\n",
        "    return None, f\"Predicción: {mp(p)}\"\n",
        "\n",
        "def predict_individual(model_name, *features):\n",
        "    _, msg = predict_model_combined(model_name, None, *features)\n",
        "    return f\"<h2>{msg}</h2>\"\n",
        "\n",
        "def predict_bulk(model_name, excel_file):\n",
        "    df, _ = predict_model_combined(model_name, excel_file)\n",
        "    return df\n",
        "\n",
        "def generate_excel_template(model_name):\n",
        "    rp = \"model_registry.json\"\n",
        "    if not os.path.exists(rp): return None\n",
        "    reg = json.load(open(rp))\n",
        "    if model_name not in reg: return None\n",
        "    headers = reg[model_name].get(\"headers\", [])\n",
        "    df = pd.DataFrame(columns=headers)\n",
        "    # nombre dinámico\n",
        "    safe = \"\".join(c if c.isalnum() else \"_\" for c in model_name)\n",
        "    fname = f\"{safe}_plantilla.xlsx\"\n",
        "    df.to_excel(fname, index=False)\n",
        "    return fname\n",
        "\n",
        "# Modelo dropdown inicia vacío\n",
        "initial_models = load_model_registry()\n",
        "\n",
        "# ---------------------------\n",
        "# INTERFAZ GRADIO PRINCIPAL\n",
        "# ---------------------------\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    # Pestaña 1: Dataset + Modelos ML\n",
        "    with gr.Tab(\"Dataset + Modelos ML\"):\n",
        "        gr.Markdown(\"## Visualización de Dataset y Comparación de Modelos (múltiples)\")\n",
        "        with gr.Row():\n",
        "            ds_sel = gr.Dropdown(list(available_datasets.keys()), value=\"Iris (Clasificación)\", label=\"Dataset\")\n",
        "            models_cb = gr.CheckboxGroup(list(classification_models.keys()), value=list(classification_models.keys()), label=\"Modelos\")\n",
        "            ts = gr.Slider(0.1,0.5,0.3,0.05, label=\"Test size\")\n",
        "        btn_train = gr.Button(\"Entrenar y Comparar\")\n",
        "        tbl_res = gr.Dataframe(headers=[\"Modelo\",\"Precisión\"], label=\"Resultados\")\n",
        "        plot_res = gr.Plot(label=\"Gráfica\")\n",
        "        file_res = gr.File(label=\"Reporte CSV\")\n",
        "        btn_train.click(full_training, [ds_sel, models_cb, ts], [tbl_res, plot_res, file_res])\n",
        "\n",
        "        df0, lbl0 = show_dataset_with_target(\"Iris (Clasificación)\")\n",
        "        dt = gr.Dataframe(value=df0); md = gr.Markdown(lbl0)\n",
        "        ds_sel.change(show_dataset_with_target, ds_sel, [dt, md])\n",
        "        ds_sel.change(update_model_choices, ds_sel, models_cb)\n",
        "\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"EDA\"):\n",
        "                eda_tbl = gr.Dataframe(value=run_eda(\"Iris (Clasificación)\"))\n",
        "                eda_plt = gr.Plot(value=plot_eda(\"Iris (Clasificación)\"))\n",
        "            with gr.Tab(\"PCA\"):\n",
        "                pca_plt = gr.Plot(value=run_pca(\"Iris (Clasificación)\"))\n",
        "        ds_sel.change(run_eda, ds_sel, eda_tbl)\n",
        "        ds_sel.change(plot_eda, ds_sel, eda_plt)\n",
        "        ds_sel.change(run_pca, ds_sel, pca_plt)\n",
        "\n",
        "    # Pestaña 2: Entrenamiento individual\n",
        "    with gr.Tab(\"Entrenamiento\"):\n",
        "        gr.Markdown(\"## Entrenamiento de un solo modelo\")\n",
        "        ds_tr = gr.Dropdown(list(available_datasets.keys()), value=\"Iris (Clasificación)\", label=\"Dataset\")\n",
        "        mdl_tr = gr.Dropdown(list(classification_models.keys()), value=list(classification_models.keys())[0], label=\"Modelo\")\n",
        "        ds_tr.change(update_model_choices, ds_tr, mdl_tr)\n",
        "        ts_tr = gr.Slider(0.1,0.5,0.3,0.05, label=\"Test size\")\n",
        "\n",
        "        # Logistic Regression sliders\n",
        "        lr_Cp = fix_slider_params(model_params_demo[\"Logistic Regression\"][\"C\"])\n",
        "        lr_Itp = fix_slider_params(model_params_demo[\"Logistic Regression\"][\"max_iter\"])\n",
        "        c_sl = gr.Slider(minimum=lr_Cp[\"minimum\"], maximum=lr_Cp[\"maximum\"],\n",
        "                         step=lr_Cp[\"step\"], value=lr_Cp[\"value\"], label=lr_Cp[\"label\"])\n",
        "        it_sl = gr.Slider(minimum=lr_Itp[\"minimum\"], maximum=lr_Itp[\"maximum\"],\n",
        "                          step=lr_Itp[\"step\"], value=lr_Itp[\"value\"], label=lr_Itp[\"label\"])\n",
        "        # Random Forest Regressor sliders\n",
        "        rf_Nep = fix_slider_params(model_params_demo[\"Random Forest Regressor\"][\"n_estimators\"])\n",
        "        rf_Mdp = fix_slider_params(model_params_demo[\"Random Forest Regressor\"][\"max_depth\"])\n",
        "        ne_sl = gr.Slider(minimum=rf_Nep[\"minimum\"], maximum=rf_Nep[\"maximum\"],\n",
        "                          step=rf_Nep[\"step\"], value=rf_Nep[\"value\"], label=rf_Nep[\"label\"], visible=False)\n",
        "        md_sl = gr.Slider(minimum=rf_Mdp[\"minimum\"], maximum=rf_Mdp[\"maximum\"],\n",
        "                          step=rf_Mdp[\"step\"], value=rf_Mdp[\"value\"], label=rf_Mdp[\"label\"], visible=False)\n",
        "\n",
        "        def show_params(name):\n",
        "            if name==\"Logistic Regression\":\n",
        "                return gr.update(visible=True), gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
        "            elif name==\"Random Forest Regressor\":\n",
        "                return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True), gr.update(visible=True)\n",
        "            else:\n",
        "                return (gr.update(visible=False),)*4\n",
        "\n",
        "        mdl_tr.change(show_params, mdl_tr, [c_sl, it_sl, ne_sl, md_sl])\n",
        "\n",
        "        btn_tr1 = gr.Button(\"Entrenar\")\n",
        "        md_out = gr.Markdown()\n",
        "        plt_out = gr.Plot()\n",
        "        tbl_out = gr.Dataframe()\n",
        "        st = gr.State()\n",
        "        btn_tr1.click(train_one_model_with_save,\n",
        "                      inputs=[ds_tr, mdl_tr, ts_tr, c_sl, it_sl, ne_sl, md_sl],\n",
        "                      outputs=[md_out, plt_out, tbl_out, st])\n",
        "\n",
        "        save_name = gr.Textbox(label=\"Nombre modelo\")\n",
        "        btn_save = gr.Button(\"Guardar\")\n",
        "        def do_save(state, name):\n",
        "            if not state: return \"Nada que guardar\"\n",
        "            path, _ = save_model_locally(state[\"model\"], name, state[\"headers\"], state[\"target_names\"])\n",
        "            return f\"Guardado en {path}\"\n",
        "        btn_save.click(do_save, [st, save_name], md_out)\n",
        "\n",
        "    # Pestaña 3: Predicción (Individual / Masiva)\n",
        "    with gr.Tab(\"Predicción\"):\n",
        "        gr.Markdown(\"## Predicción\\n- **Individual** vs **Masiva**\")\n",
        "\n",
        "        # Ahora sin placeholder\n",
        "        model_dd = gr.Dropdown(\n",
        "            choices=load_model_registry(),\n",
        "            value=None,\n",
        "            label=\"Modelos guardados\"\n",
        "        )\n",
        "\n",
        "        btn_ref = gr.Button(\"Refrescar modelos\")\n",
        "        btn_ref.click(refresh_model_list, [], model_dd)\n",
        "\n",
        "        with gr.Tabs():\n",
        "            # Individual\n",
        "            with gr.Tab(\"Individual\"):\n",
        "                feature_inputs = [\n",
        "                    gr.Textbox(label=f\"Feature {i}\", visible=False)\n",
        "                    for i in range(MAX_FEATURES)\n",
        "                ]\n",
        "                model_dd.change(update_textboxes_from_saved_model,\n",
        "                                inputs=[model_dd],\n",
        "                                outputs=feature_inputs)\n",
        "                btn_ind = gr.Button(\"Predecir\")\n",
        "                out_ind = gr.HTML()\n",
        "                btn_ind.click(predict_individual,\n",
        "                              inputs=[model_dd] + feature_inputs,\n",
        "                              outputs=[out_ind])\n",
        "\n",
        "            # Masiva\n",
        "            with gr.Tab(\"Masiva\"):\n",
        "                tpl_btn = gr.Button(\"Generar plantilla Excel\")\n",
        "                tpl_file = gr.File(label=\"Descargar plantilla Excel\")\n",
        "                tpl_btn.click(generate_excel_template,\n",
        "                              inputs=[model_dd],\n",
        "                              outputs=[tpl_file])\n",
        "                uploader = gr.File(label=\"Cargar Excel\",\n",
        "                                   file_types=[\".xlsx\", \".xls\"])\n",
        "                btn_bulk = gr.Button(\"Predecir Masivo\")\n",
        "                out_bulk = gr.Dataframe(label=\"Resultados Masivos\")\n",
        "                btn_bulk.click(predict_bulk,\n",
        "                               inputs=[model_dd, uploader],\n",
        "                               outputs=[out_bulk])\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "38tm4diBGhsm"
      }
    }
  ]
}