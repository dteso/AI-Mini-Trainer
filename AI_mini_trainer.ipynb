{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXdCX3VulKtO+sjHYYphvQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dteso/AI-Mini-Trainer/blob/main/AI_mini_trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio scikit-learn pandas plotly atomicwrites"
      ],
      "metadata": {
        "id": "kyc-HbLlkucd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qquUaEtQkbgu"
      },
      "outputs": [],
      "source": [
        "### ML Mini Trainer - v1.0.1\n",
        "### DAVID TESO POZO - 2025\n",
        "\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import pickle\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import gradio as gr\n",
        "from atomicwrites import atomic_write\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.datasets import (\n",
        "    load_iris, load_wine, load_breast_cancer, load_digits,\n",
        "    load_diabetes, fetch_california_housing,\n",
        "    make_regression, make_friedman1\n",
        ")\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, classification_report,\n",
        "    r2_score, mean_squared_error\n",
        ")\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# --- Rutas y carpetas ---\n",
        "DATASET_REGISTRY = \"dataset_registry.json\"\n",
        "MODEL_REGISTRY   = \"model_registry.json\"\n",
        "os.makedirs(\"datasets\", exist_ok=True)\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# ---------------------------\n",
        "# DATASETS PREDEFINIDOS\n",
        "# ---------------------------\n",
        "available_datasets = {\n",
        "    \"Iris (Clasificaci√≥n)\": load_iris,\n",
        "    \"Wine (Clasificaci√≥n)\": load_wine,\n",
        "    \"Breast Cancer (Clasificaci√≥n)\": load_breast_cancer,\n",
        "    \"Digits (Clasificaci√≥n)\": load_digits,\n",
        "    \"Diabetes (Regresi√≥n)\": load_diabetes,\n",
        "    \"California Housing (Regresi√≥n)\": fetch_california_housing,\n",
        "    \"Friedman1 (Sint√©tico)\": lambda: {\n",
        "        \"data\": make_friedman1(n_samples=200, n_features=10, random_state=42)[0],\n",
        "        \"target\": make_friedman1(n_samples=200, n_features=10, random_state=42)[1],\n",
        "        \"feature_names\": [f\"X{i}\" for i in range(10)]\n",
        "    },\n",
        "    \"Make Regression (Sint√©tico)\": lambda: {\n",
        "        \"data\": make_regression(n_samples=200, n_features=8, noise=0.1, random_state=42)[0],\n",
        "        \"target\": make_regression(n_samples=200, n_features=8, noise=0.1, random_state=42)[1],\n",
        "        \"feature_names\": [f\"X{i}\" for i in range(8)]\n",
        "    },\n",
        "}\n",
        "\n",
        "classification_models = {\n",
        "    \"Logistic Regression\": LogisticRegression,\n",
        "    \"KNN Classifier\": KNeighborsClassifier,\n",
        "    \"Decision Tree Classifier\": DecisionTreeClassifier,\n",
        "    \"Random Forest Classifier\": RandomForestClassifier,\n",
        "    \"SVC\": SVC,\n",
        "    \"Naive Bayes\": GaussianNB,\n",
        "}\n",
        "\n",
        "regression_models = {\n",
        "    \"Linear Regression\": LinearRegression,\n",
        "    \"Random Forest Regressor\": RandomForestRegressor\n",
        "}\n",
        "\n",
        "available_models = {**classification_models, **regression_models}\n",
        "\n",
        "# ---------------------------\n",
        "# REGISTRO DE DATASETS\n",
        "# ---------------------------\n",
        "def load_dataset_registry():\n",
        "    names = list(available_datasets.keys())\n",
        "    if os.path.exists(DATASET_REGISTRY):\n",
        "        try:\n",
        "            reg = json.load(open(DATASET_REGISTRY))\n",
        "            names += list(reg.keys())\n",
        "        except:\n",
        "            pass\n",
        "    return names\n",
        "\n",
        "def register_dataset(file, name):\n",
        "    if not name or name in available_datasets:\n",
        "        return \"‚ùå Nombre inv√°lido o ya existe.\"\n",
        "    ext = os.path.splitext(file.name)[1].lower()\n",
        "    if ext not in [\".csv\", \".xlsx\", \".xls\"]:\n",
        "        return \"‚ùå Solo CSV o Excel.\"\n",
        "    dest = os.path.join(\"datasets\", f\"{name}{ext}\")\n",
        "    shutil.copy(file.name, dest)\n",
        "    reg = json.load(open(DATASET_REGISTRY)) if os.path.exists(DATASET_REGISTRY) else {}\n",
        "    reg[name] = dest\n",
        "    with atomic_write(DATASET_REGISTRY, overwrite=True, encoding=\"utf-8\") as f:\n",
        "        json.dump(reg, f, indent=4)\n",
        "    return f\"‚úÖ Dataset '{name}' registrado.\"\n",
        "\n",
        "# ---------------------------\n",
        "# CARGA Y VISTA PREVIA\n",
        "# ---------------------------\n",
        "def load_dataset(name):\n",
        "    if name in available_datasets:\n",
        "        data = available_datasets[name]()\n",
        "        df = pd.DataFrame(data[\"data\"], columns=data.get(\"feature_names\"))\n",
        "        return df, pd.Series(data[\"target\"], name=\"target\"), data.get(\"target_names\")\n",
        "    reg = json.load(open(DATASET_REGISTRY))\n",
        "    path = reg[name]\n",
        "    if path.endswith(\".csv\"):\n",
        "        df_full = pd.read_csv(path)\n",
        "    else:\n",
        "        df_full = pd.read_excel(path)\n",
        "    if \"target\" not in df_full.columns:\n",
        "        raise ValueError(\"‚ùå El dataset debe tener columna 'target'.\")\n",
        "    return df_full.drop(columns=[\"target\"]), df_full[\"target\"], None\n",
        "\n",
        "def show_dataset_with_target(name):\n",
        "    df, target, tns = load_dataset(name)\n",
        "    labels = ([tns[int(x)] for x in target] if tns is not None else target.tolist())\n",
        "    preview = df.copy()\n",
        "    preview[\"class\"] = labels\n",
        "    return preview, f\"Vista del Dataset ({len(preview)} filas)\"\n",
        "\n",
        "# ---------------------------\n",
        "# Detecci√≥n de clasificaci√≥n\n",
        "# ---------------------------\n",
        "def is_classification_task(target):\n",
        "    return pd.Series(target).nunique() < 20\n",
        "\n",
        "# ---------------------------\n",
        "# ENTRENAMIENTO M√öLTIPLE\n",
        "# ---------------------------\n",
        "def update_model_choices(ds):\n",
        "    df, target, _ = load_dataset(ds)\n",
        "    if is_classification_task(target):\n",
        "        return gr.update(choices=list(classification_models.keys()),\n",
        "                         value=list(classification_models.keys())[0])\n",
        "    else:\n",
        "        return gr.update(choices=list(regression_models.keys()),\n",
        "                         value=list(regression_models.keys())[0])\n",
        "\n",
        "def train_multiple(ds, mods, ts):\n",
        "    df, target, _ = load_dataset(ds)\n",
        "    clf_task = is_classification_task(target)\n",
        "    if clf_task:\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(target)\n",
        "    else:\n",
        "        y = target\n",
        "    Xtr, Xte, ytr, yte = train_test_split(df, y, test_size=ts, random_state=42)\n",
        "    results = []\n",
        "    for m in mods:\n",
        "        Model = available_models[m]()\n",
        "        Model.fit(Xtr, ytr)\n",
        "        pred = Model.predict(Xte)\n",
        "        if clf_task:\n",
        "            metr = accuracy_score(yte, pred)\n",
        "            rpt = classification_report(yte, pred, output_dict=True)\n",
        "        else:\n",
        "            metr = r2_score(yte, pred)\n",
        "            mse = mean_squared_error(yte, pred)\n",
        "            rpt = {\"R2\": metr, \"MSE\": mse}\n",
        "        results.append({\"Modelo\": m, \"Precisi√≥n\": metr, \"Reporte\": rpt})\n",
        "    return results\n",
        "\n",
        "def plot_compare(res):\n",
        "    fig, ax = plt.subplots()\n",
        "    vals = [r[\"Precisi√≥n\"] for r in res]\n",
        "    sns.barplot(x=[r[\"Modelo\"] for r in res], y=vals, ax=ax)\n",
        "    if all(0<=v<=1 for v in vals):\n",
        "        ax.set_ylim(0,1); ax.set_ylabel(\"Accuracy\")\n",
        "    else:\n",
        "        ax.set_ylabel(\"R2 Score\")\n",
        "    ax.tick_params(axis=\"x\", rotation=45)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def export_csv(res):\n",
        "    df = pd.DataFrame([{\"Modelo\":r[\"Modelo\"], \"Precisi√≥n\":r[\"Precisi√≥n\"]} for r in res])\n",
        "    return df.to_csv(index=False)\n",
        "\n",
        "def full_training(ds, mods, ts):\n",
        "    res = train_multiple(ds, mods, ts)\n",
        "    df_res = pd.DataFrame(\n",
        "        [{\"Modelo\":r[\"Modelo\"], \"Precisi√≥n\":round(r[\"Precisi√≥n\"],4)} for r in res]\n",
        "    ).sort_values(\"Precisi√≥n\", ascending=False)\n",
        "    fig = plot_compare(res)\n",
        "    path = \"report.csv\"\n",
        "    open(path,\"w\").write(export_csv(res))\n",
        "    return df_res, fig, path\n",
        "\n",
        "def run_eda(ds):\n",
        "    df, _, _ = load_dataset(ds)\n",
        "    return df.describe().reset_index()\n",
        "\n",
        "def plot_eda(ds):\n",
        "    df, _, _ = load_dataset(ds)\n",
        "    m = df.melt(var_name=\"feature\", value_name=\"valor\")\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    sns.boxplot(data=m, x=\"feature\", y=\"valor\", hue=\"feature\", dodge=False, ax=ax)\n",
        "    if ax.get_legend(): ax.get_legend().remove()\n",
        "    ax.tick_params(axis=\"x\", rotation=30)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "def run_pca(ds):\n",
        "    df, _, _ = load_dataset(ds)\n",
        "    comps = PCA(n_components=2).fit_transform(df)\n",
        "    dfp = pd.DataFrame(comps, columns=[\"PC1\",\"PC2\"])\n",
        "    fig, ax = plt.subplots(figsize=(8,6))\n",
        "    sns.scatterplot(data=dfp, x=\"PC1\", y=\"PC2\", s=60, ax=ax)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# ---------------------------\n",
        "# ENTRENAMIENTO INDIVIDUAL & GUARDADO\n",
        "# ---------------------------\n",
        "model_params = {\n",
        "    \"Logistic Regression\":[(\"C\",0.01,10,0.01,1),(\"max_iter\",100,2000,100,1000)],\n",
        "    \"KNN Classifier\":[(\"n_neighbors\",1,30,1,5)],\n",
        "    \"Decision Tree Classifier\":[(\"max_depth\",1,20,1,10),(\"min_samples_split\",2,20,1,2)],\n",
        "    \"Random Forest Classifier\":[(\"n_estimators\",10,200,10,100),(\"max_depth\",1,20,1,10)],\n",
        "    \"SVC\":[(\"C\",0.1,10,0.1,1),(\"gamma\",0.001,1,0.001,0.01)],\n",
        "    \"Naive Bayes\":[],\n",
        "    \"Linear Regression\":[],\n",
        "    \"Random Forest Regressor\":[(\"n_estimators\",10,200,10,100),(\"max_depth\",1,20,1,5)]\n",
        "}\n",
        "\n",
        "def save_model_locally(model, name, headers, tns):\n",
        "    if not name.endswith(\".pkl\"):\n",
        "        name += \".pkl\"\n",
        "    path = os.path.join(\"models\", name)\n",
        "    pickle.dump({\"model\":model,\"headers\":headers,\"target_names\":tns}, open(path,\"wb\"))\n",
        "    reg = json.load(open(MODEL_REGISTRY)) if os.path.exists(MODEL_REGISTRY) else {}\n",
        "    reg[name] = {\"model_path\":path,\"headers\":headers,\"target_names\":tns}\n",
        "    with atomic_write(MODEL_REGISTRY, overwrite=True, encoding=\"utf-8\") as f:\n",
        "        json.dump(reg, f, indent=4)\n",
        "    return path\n",
        "\n",
        "def train_one_model_with_save(\n",
        "    ds, mname, ts,\n",
        "    v1,v2,v3,v4,v5,v6,v7,v8,v9,v10,v11\n",
        "):\n",
        "    df, target, tns = load_dataset(ds)\n",
        "    clf_task = is_classification_task(target)\n",
        "    if clf_task:\n",
        "        le = LabelEncoder()\n",
        "        y = le.fit_transform(target)\n",
        "        if tns is None:\n",
        "            tns = list(le.classes_)\n",
        "    else:\n",
        "        y = target\n",
        "    Xtr, Xte, ytr, yte = train_test_split(df, y, test_size=ts, random_state=42)\n",
        "\n",
        "    # hiperparams & safe-KNN\n",
        "    if mname==\"Logistic Regression\":\n",
        "        hyper={\"C\":v1,\"max_iter\":int(v2)}; Cls=LogisticRegression\n",
        "    elif mname==\"KNN Classifier\":\n",
        "        k_req=int(v3); k=min(k_req, len(Xtr)); hyper={\"n_neighbors\":k}; Cls=KNeighborsClassifier\n",
        "    elif mname==\"Decision Tree Classifier\":\n",
        "        hyper={\"max_depth\":int(v4),\"min_samples_split\":int(v5)}; Cls=DecisionTreeClassifier\n",
        "    elif mname==\"Random Forest Classifier\":\n",
        "        hyper={\"n_estimators\":int(v6),\"max_depth\":int(v7)}; Cls=RandomForestClassifier\n",
        "    elif mname==\"SVC\":\n",
        "        hyper={\"C\":v8,\"gamma\":v9}; Cls=SVC\n",
        "    elif mname==\"Naive Bayes\":\n",
        "        hyper={}; Cls=GaussianNB\n",
        "    elif mname==\"Random Forest Regressor\":\n",
        "        hyper={\"n_estimators\":int(v10),\"max_depth\":int(v11)}; Cls=RandomForestRegressor\n",
        "    elif mname==\"Linear Regression\":\n",
        "        hyper={}; Cls=LinearRegression\n",
        "    else:\n",
        "        raise ValueError(\"Modelo no soportado\")\n",
        "\n",
        "    model = Cls(**hyper)\n",
        "    model.fit(Xtr, ytr)\n",
        "    y_pred = model.predict(Xte)\n",
        "\n",
        "    if clf_task:\n",
        "        metric=accuracy_score(yte,y_pred); title=\"Accuracy\"\n",
        "        from sklearn.metrics import confusion_matrix\n",
        "        cm=confusion_matrix(yte,y_pred)\n",
        "        fig,ax=plt.subplots()\n",
        "        sns.heatmap(cm,annot=True,fmt=\"d\",cmap=\"Blues\",ax=ax)\n",
        "        ax.set_title(\"Confusion Matrix\")\n",
        "        table_df=pd.DataFrame({\"y_true\":yte,\"y_pred\":y_pred})\n",
        "    else:\n",
        "        metric=r2_score(yte,y_pred); title=\"R2 Score\"\n",
        "        fig,ax=plt.subplots()\n",
        "        ax.scatter(yte,y_pred)\n",
        "        ax.plot([yte.min(),yte.max()],[yte.min(),yte.max()],\"k--\",lw=2)\n",
        "        ax.set_title(\"Actual vs Predicted\")\n",
        "        table_df=pd.DataFrame({\"Actual\":yte,\"Predicted\":y_pred})\n",
        "\n",
        "    state={\"model\":model,\"headers\":df.columns.tolist(),\"target_names\":tns}\n",
        "    return f\"{title}: {metric:.4f}\", fig, table_df, state, hyper\n",
        "\n",
        "def save_trained_model(state, save_name):\n",
        "    if not state or \"model\" not in state:\n",
        "        return \"‚ùå No hay modelo entrenado para guardar.\"\n",
        "    path = save_model_locally(\n",
        "        state[\"model\"],\n",
        "        save_name,\n",
        "        state[\"headers\"],\n",
        "        state[\"target_names\"]\n",
        "    )\n",
        "    return f\"‚úÖ Modelo guardado en: `{path}`\"\n",
        "\n",
        "# ---------------------------\n",
        "# PREDICCI√ìN\n",
        "# ---------------------------\n",
        "MAX_F=20\n",
        "\n",
        "def load_model_list():\n",
        "    return list(json.load(open(MODEL_REGISTRY)).keys()) if os.path.exists(MODEL_REGISTRY) else []\n",
        "\n",
        "def refresh_models():\n",
        "    return gr.update(choices=load_model_list())\n",
        "\n",
        "def update_feats(m):\n",
        "    reg=json.load(open(MODEL_REGISTRY))\n",
        "    hdr=reg[m][\"headers\"]\n",
        "    ups=[]\n",
        "    for i in range(MAX_F):\n",
        "        if i<len(hdr):\n",
        "            ups.append(gr.update(label=hdr[i],visible=True,value=\"\"))\n",
        "        else:\n",
        "            ups.append(gr.update(visible=False))\n",
        "    return ups\n",
        "\n",
        "def predict_model_combined(selected_model_name, excel_file, *features):\n",
        "    reg=json.load(open(MODEL_REGISTRY))\n",
        "    entry=reg[selected_model_name]\n",
        "    with open(entry[\"model_path\"],\"rb\") as f:\n",
        "        loaded=pickle.load(f)\n",
        "    model=loaded[\"model\"]\n",
        "    headers=loaded[\"headers\"]\n",
        "    tns=loaded.get(\"target_names\",None)\n",
        "\n",
        "    def map_pred(p):\n",
        "        if tns is not None:\n",
        "            try: return tns[int(p)]\n",
        "            except: return p\n",
        "        return p\n",
        "\n",
        "    if excel_file is not None:\n",
        "        fn=excel_file.name; ext=os.path.splitext(fn)[1].lower()\n",
        "        df=(pd.read_excel(fn,engine=\"openpyxl\") if ext in [\".xls\",\".xlsx\"] else pd.read_csv(fn))\n",
        "        if not set(headers).issubset(df.columns):\n",
        "            return None, f\"‚ùå Faltan columnas: {headers}\"\n",
        "        preds=model.predict(df[headers])\n",
        "        df[\"Predicci√≥n\"]=[map_pred(p) for p in preds]\n",
        "        return df, \"\"\n",
        "    vals=[]\n",
        "    for i in range(len(headers)):\n",
        "        s=features[i] if i<len(features) else \"\"\n",
        "        try: vals.append(float(s))\n",
        "        except: return None, f\"‚ùå '{headers[i]}' debe ser num√©rico.\"\n",
        "    row=pd.DataFrame([vals],columns=headers)\n",
        "    try: p=model.predict(row)[0]\n",
        "    except Exception as e:\n",
        "        return None, f\"‚ö†Ô∏è Error en predicci√≥n: {e}\"\n",
        "    return None, f\"Predicci√≥n: {map_pred(p)}\"\n",
        "\n",
        "def predict_ind(m,*f):\n",
        "    _,txt = predict_model_combined(m,None,*f)\n",
        "    return f\"<h2>{txt}</h2>\"\n",
        "\n",
        "def predict_bulk(m,excel):\n",
        "    df,_=predict_model_combined(m,excel)\n",
        "    return df\n",
        "\n",
        "def gen_template(m):\n",
        "    reg=json.load(open(MODEL_REGISTRY))\n",
        "    hdr=reg[m][\"headers\"]\n",
        "    df=pd.DataFrame(columns=hdr)\n",
        "    fn=f\"{m.replace(' ','_')}_plantilla.xlsx\"\n",
        "    df.to_excel(fn,index=False)\n",
        "    return fn\n",
        "\n",
        "# ---------------------------\n",
        "# INTERFAZ\n",
        "# ---------------------------\n",
        "initial_datasets=load_dataset_registry()\n",
        "initial_models=load_model_list()\n",
        "\n",
        "with gr.Blocks(theme=gr.themes.Soft(primary_hue=\"blue\")) as demo:\n",
        "\n",
        "    gr.Markdown(\"# ü§ñ AI Mini Trainer\\n_Una herramienta ligera para ML_\")\n",
        "\n",
        "    # PESTA√ëA 1: DATASET + COMPARACI√ìN\n",
        "    with gr.Tab(\"üìä Dataset + Modelos ML\"):\n",
        "        gr.Markdown(\"### Explora, registra y compara modelos\")\n",
        "\n",
        "        with gr.Row():\n",
        "            # COLUMNA IZQUIERDA: selector + refrescar\n",
        "            with gr.Column(scale=1):\n",
        "                ds_sel = gr.Dropdown(initial_datasets, value=initial_datasets[0], label=\"Dataset\")\n",
        "                ref_btn = gr.Button(\"Refrescar\")\n",
        "                ref_btn.click(lambda: gr.update(choices=load_dataset_registry()),\n",
        "                              [], [ds_sel])\n",
        "\n",
        "            # COLUMNA DERECHA: upload, nombre, guardar\n",
        "            with gr.Column(scale=1):\n",
        "                up_ds = gr.File(label=\"Subir CSV/Excel\")\n",
        "                nm_ds = gr.Textbox(label=\"Nombre\")\n",
        "                sv_btn = gr.Button(\"Guardar\")\n",
        "                msg_ds= gr.Markdown()\n",
        "                sv_btn.click(register_dataset, [up_ds, nm_ds], [msg_ds])\n",
        "\n",
        "        models_cb = gr.CheckboxGroup(list(classification_models.keys()),\n",
        "                                     value=list(classification_models.keys()),\n",
        "                                     label=\"Modelos\")\n",
        "        ts_cb     = gr.Slider(0.1,0.5,0.3,0.05, label=\"Test size\")\n",
        "        btn_tr    = gr.Button(\"Entrenar y Comparar\")\n",
        "        tbl_res   = gr.Dataframe(headers=[\"Modelo\",\"Precisi√≥n\"])\n",
        "        plt_res   = gr.Plot()\n",
        "        csv_res   = gr.File()\n",
        "        btn_tr.click(full_training, [ds_sel, models_cb, ts_cb], [tbl_res, plt_res, csv_res])\n",
        "\n",
        "        df0, lbl0 = show_dataset_with_target(initial_datasets[0])\n",
        "        tbl0  = gr.Dataframe(value=df0)\n",
        "        lbl0c = gr.Markdown(lbl0)\n",
        "        ds_sel.change(show_dataset_with_target, [ds_sel], [tbl0, lbl0c])\n",
        "        ds_sel.change(update_model_choices, [ds_sel], [models_cb])\n",
        "\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"EDA\"):\n",
        "                eda_t = gr.Dataframe(value=run_eda(initial_datasets[0]))\n",
        "                eda_p = gr.Plot(value=plot_eda(initial_datasets[0]))\n",
        "                ds_sel.change(run_eda, [ds_sel], [eda_t])\n",
        "                ds_sel.change(plot_eda, [ds_sel], [eda_p])\n",
        "            with gr.Tab(\"PCA\"):\n",
        "                pca_p = gr.Plot(value=run_pca(initial_datasets[0]))\n",
        "                ds_sel.change(run_pca, [ds_sel], [pca_p])\n",
        "\n",
        "    # PESTA√ëA 2: ENTRENAMIENTO INDIVIDUAL\n",
        "    with gr.Tab(\"‚öôÔ∏è Entrenamiento\"):\n",
        "        gr.Markdown(\"### Ajusta hiperpar√°metros y guarda modelo\")\n",
        "        ds_tr = gr.Dropdown(initial_datasets, value=initial_datasets[0], label=\"Dataset\")\n",
        "        ref2 = gr.Button(\"Refrescar\")\n",
        "        ref2.click(lambda: gr.update(choices=load_dataset_registry()), [], [ds_tr])\n",
        "        _, tgt0, _ = load_dataset(initial_datasets[0])\n",
        "        init_mods = list(classification_models.keys()) if is_classification_task(tgt0) else list(regression_models.keys())\n",
        "        mdl_tr = gr.Dropdown(init_mods, value=init_mods[0], label=\"Modelo\")\n",
        "        ds_tr.change(update_model_choices, [ds_tr], [mdl_tr])\n",
        "        ts_tr = gr.Slider(0.1,0.5,0.3,0.05, label=\"Test size\")\n",
        "\n",
        "        sliders = []\n",
        "        for m, params in model_params.items():\n",
        "            for (_n,mn,mx,stp,dfv) in params:\n",
        "                sliders.append(gr.Slider(mn,mx,value=dfv,step=stp,label=_n,visible=False))\n",
        "\n",
        "        def show_params(name):\n",
        "            return [gr.update(visible=(name==mod)) for mod in model_params for _ in model_params[mod]]\n",
        "\n",
        "        mdl_tr.change(show_params, [mdl_tr], sliders)\n",
        "\n",
        "        train_btn = gr.Button(\"Entrenar\")\n",
        "        out_md    = gr.Markdown(\"Sin entrenar\")\n",
        "        out_pl    = gr.Plot()\n",
        "        out_tb    = gr.Dataframe()\n",
        "        st        = gr.State()\n",
        "        train_btn.click(train_one_model_with_save,\n",
        "                        [ds_tr, mdl_tr, ts_tr] + sliders,\n",
        "                        [out_md, out_pl, out_tb, st])\n",
        "\n",
        "        save_name = gr.Textbox(label=\"Nombre para guardar\")\n",
        "        gr.Button(\"Guardar modelo\").click(save_trained_model, [st, save_name], [out_md])\n",
        "\n",
        "    # PESTA√ëA 3: PREDICCI√ìN\n",
        "    with gr.Tab(\"üîÆ Predicci√≥n\"):\n",
        "        gr.Markdown(\"### Predicci√≥n individual y masiva\")\n",
        "        mdl_dd = gr.Dropdown(initial_models, value=None, label=\"Modelos guardados\")\n",
        "        ref3   = gr.Button(\"Refrescar\")\n",
        "        ref3.click(refresh_models, [], [mdl_dd])\n",
        "\n",
        "        with gr.Tabs():\n",
        "            with gr.Tab(\"Individual\"):\n",
        "                feats = [gr.Textbox(visible=False) for _ in range(MAX_F)]\n",
        "                mdl_dd.change(update_feats, [mdl_dd], feats)\n",
        "                btn_i = gr.Button(\"Predecir\")\n",
        "                out_i = gr.HTML()\n",
        "                btn_i.click(predict_ind, [mdl_dd] + feats, [out_i])\n",
        "\n",
        "            with gr.Tab(\"Masiva\"):\n",
        "                tpl_btn = gr.Button(\"Generar plantilla Excel\")\n",
        "                tpl_f   = gr.File(label=\"Descargar plantilla\")\n",
        "                tpl_btn.click(gen_template, [mdl_dd], [tpl_f])\n",
        "                up_xl   = gr.File(label=\"Cargar Excel\")\n",
        "                btn_b   = gr.Button(\"Predecir Masivo\")\n",
        "                out_b   = gr.Dataframe()\n",
        "                btn_b.click(predict_bulk, [mdl_dd, up_xl], [out_b])\n",
        "\n",
        "demo.launch(share=True, debug=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "38tm4diBGhsm"
      }
    }
  ]
}